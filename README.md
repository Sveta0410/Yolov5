# Детектирование драк и падений


## Вступление

Данный репозиторий включает в себя код, необходимый для развёртывания веб-сервиса, 
основанного на нейросетевой детектирующей модели с последующим отслеживанием объектов на видеозаписи,
с реализованным сбором статистики в базу данных, с использованием фреймворка для передачи обработанных потоковых данных.


## Установка и запуск
Для запуска потребуется python v3.5+, postgreSQL

Склонируйте репозиторий себе на компьютер, перейдите в директорию с ним и выполните установку необходимых модулей
```sh
git clone https://github.com/DanilaBelskiy/Website_CV.git
cd Website_CV
pip install --upgrade pip
pip install -r requirements.txt
```
Запускаем приложение командой

```sh
python3 main.py 
```

После этого переходим по адресу http:/localhost:9000/ и наблюдаем результат

## Запуск через docker-compose

Cклонируйте репозиторий себе на компьютер, перейдите в директорию с ним и выполните команду

```sh
git clone https://github.com/DanilaBelskiy/Website_CV.git
cd Website_CV
docker-compose up
```
Чтобы остановить сервер, в этой же директории вызываем 
```sh
docker-compose stop
```

## Запуск тестов
Тесты можно запустить командой

```sh
python3 all_test.py
```


[//]: # (<div align="center">)

[//]: # (<p>)

[//]: # (<img src="MOT16_eval/track_pedestrians.gif" width="400"/> <img src="MOT16_eval/track_all.gif" width="400"/> )

[//]: # (</p>)

[//]: # (<br>)

[//]: # (<div>)

[//]: # (<a href="https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch/actions"><img src="https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch/workflows/CI%20CPU%20testing/badge.svg" alt="CI CPU testing"></a>)

[//]: # (<br>  )

[//]: # (<a href="https://colab.research.google.com/drive/18nIqkBr68TkK8dHdarxTco6svHUJGggY?usp=sharing"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a>)

[//]: # ( )
[//]: # (</div>)

[//]: # ()
[//]: # (</div>)

[//]: # ()
[//]: # ()
[//]: # (## Introduction)

[//]: # ()
[//]: # (This repository contains a highly configurable two-stage-tracker that adjusts to different deployment scenarios. The detections generated by [YOLOv5]&#40;https://github.com/ultralytics/yolov5&#41;, a family of object detection architectures and models pretrained on the COCO dataset, are passed to a [Deep Sort algorithm]&#40;https://github.com/ZQPei/deep_sort_pytorch&#41; which tracks the objects. It can track any object that your Yolov5 model was trained to detect.)

[//]: # ()
[//]: # ()
[//]: # (## Tutorials)

[//]: # ()
[//]: # (* [Yolov5 training on Custom Data &#40;link to external repository&#41;]&#40;https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data&#41;&nbsp;)

[//]: # (* [DeepSort deep descriptor training &#40;link to external repository&#41;]&#40;https://kaiyangzhou.github.io/deep-person-reid/user_guide.html&#41;&nbsp;)

[//]: # (* [Yolov5 deep_sort pytorch evaluation]&#40;https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch/wiki/Evaluation&#41;&nbsp;)

[//]: # ()
[//]: # ()
[//]: # ()
[//]: # (## Before you run the tracker)

[//]: # ()
[//]: # (1. Clone the repository recursively:)

[//]: # ()
[//]: # (`git clone --recurse-submodules https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch.git`)

[//]: # ()
[//]: # (If you already cloned and forgot to use `--recurse-submodules` you can run `git submodule update --init`)

[//]: # ()
[//]: # (2. Make sure that you fulfill all the requirements: Python 3.8 or later with all [requirements.txt]&#40;https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch/blob/master/requirements.txt&#41; dependencies installed, including torch>=1.7. To install, run:)

[//]: # ()
[//]: # (`pip install -r requirements.txt`)

[//]: # ()
[//]: # ()
[//]: # (## Tracking sources)

[//]: # ()
[//]: # (Tracking can be run on most video formats)

[//]: # ()
[//]: # (```bash)

[//]: # ($ python track.py --source 0  # webcam)

[//]: # (                           img.jpg  # image)

[//]: # (                           vid.mp4  # video)

[//]: # (                           path/  # directory)

[//]: # (                           path/*.jpg  # glob)

[//]: # (                           'https://youtu.be/Zgi9g1ksQHc'  # YouTube)

[//]: # (                           'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream)

[//]: # (```)

[//]: # ()
[//]: # ()
[//]: # (## Select object detection and ReID model)

[//]: # ()
[//]: # (### Yolov5)

[//]: # ()
[//]: # (There is a clear trade-off between model inference speed and accuracy. In order to make it possible to fulfill your inference speed/accuracy needs)

[//]: # (you can select a Yolov5 family model for automatic download)

[//]: # ()
[//]: # (```bash)

[//]: # ()
[//]: # ()
[//]: # ($ python track.py --source 0 --yolo_model yolov5n.pt --img 640)

[//]: # (                                          yolov5s.pt)

[//]: # (                                          yolov5m.pt)

[//]: # (                                          yolov5l.pt )

[//]: # (                                          yolov5x.pt --img 1280)

[//]: # (                                          ...)

[//]: # (```)

[//]: # ()
[//]: # (### DeepSort)

[//]: # ()
[//]: # (The above applies to DeepSort models as well. Choose a ReID model based on your needs from this ReID [model zoo]&#40;https://kaiyangzhou.github.io/deep-person-reid/MODEL_ZOO&#41;)

[//]: # ()
[//]: # (```bash)

[//]: # ()
[//]: # ()
[//]: # ($ python track.py --source 0 --deep_sort_model osnet_x0_5_market1501)

[//]: # (                                               resnet50_MSMT17)

[//]: # (                                               mobilenetv2_x1_4_dukemtmcreid)

[//]: # (                                               ...)

[//]: # (```)

[//]: # ()
[//]: # (## Filter tracked classes)

[//]: # ()
[//]: # (By default the tracker tracks all MS COCO classes.)

[//]: # ()
[//]: # (If you only want to track persons I recommend you to get [these weights]&#40;https://drive.google.com/file/d/1gglIwqxaH2iTvy6lZlXuAcMpd_U0GCUb/view?usp=sharing&#41; for increased performance)

[//]: # ()
[//]: # (```bash)

[//]: # (python3 track.py --source 0 --yolo_model yolov5/weights/crowdhuman_yolov5m.pt --classes 0  # tracks persons, only)

[//]: # (```)

[//]: # ()
[//]: # (If you want to track a subset of the MS COCO classes, add their corresponding index after the classes flag)

[//]: # ()
[//]: # (```bash)

[//]: # (python3 track.py --source 0 --yolo_model yolov5s.pt --classes 16 17  # tracks cats and dogs, only)

[//]: # (```)

[//]: # ()
[//]: # ([Here]&#40;https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/&#41; is a list of all the possible objects that a Yolov5 model trained on MS COCO can detect. Notice that the indexing for the classes in this repo starts at zero.)

[//]: # ()
[//]: # ()
[//]: # (## MOT compliant results)

[//]: # ()
[//]: # (Can be saved to your experiment folder `track/expN` by )

[//]: # ()
[//]: # (```bash)

[//]: # (python3 track.py --source ... --save-txt)

[//]: # (```)
